{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.사이킷런의 기본적인 흐름 이해하기\n",
    "- 사이킷런을 이용하여 붓꽃(Iris) 데이터 품종 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 데이터 가지고오기\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 분류의 모델로 DT사용하기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 데이터를 나누기 위해서 사용하기.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 & 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/01.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩합니다. \n",
    "iris = load_iris() #문제 + 정답지\n",
    "\n",
    "# iris.data는 Iris 데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다. \n",
    "iris_data = iris.data #문제지\n",
    "\n",
    "# iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가지고 있습니다. \n",
    "iris_label = iris.target #정답지\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다. \n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names) #정답지 없이, 데이터 밀어넣은 것, \n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)\n",
    "iris_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분리하기 : train_test_split, X, y, 비율, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문제 : iris_data\n",
    "#정답 : iris_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data,\n",
    "    iris_label,\n",
    "    test_size=0.2, #20%를 테스트로 떼어낸다. \n",
    "    random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 간단한 DT에 대한 분류 모델 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1234, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeClassifier 객체 생성 \n",
    "# 1)모델 불러오기,,,,, 학습아님,\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "# 학습 수행  --->\n",
    "# 2) 불러온 모델에 대해서 최적의 파라미터를 찾는중!!! 주어진 데이터(x_train, y_train )를 바탕으로 찾아가는 과정!!\n",
    "# fit을 통해서 학습을 수행... 파라미터 최적화 수행..\n",
    "#dt_clf.fit(iris_data, iris_labels) #컨닝하는거, 평가가 불가능해 => 모델성능이 좋을 수밖에 없어.\n",
    "dt_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델을 바탕으로 X_test에 대해서 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 1, 0, 0, 0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 0, 2, 1, 1, 1,\n",
       "       1, 1, 2, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행. \n",
    "pred = dt_clf.predict(X_test) #시험문제만 던져주면 돼\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실전 문제에 대해서 푼 값들에 대한 평가를 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p>정리 </p>\n",
    "- 데이터 불러오기<br>\n",
    "- (분석하기 위한 데이터 전처리 과정 수행) <br>\n",
    "- 데이터 분리하기<br>\n",
    "- 모델 학습하기 <br>\n",
    "- (모델에 대한 최적화 수행) <br>\n",
    "- 모델 평가하기 <br>\n",
    "- (여러 모델에 대한 종합적인 모델) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. SckiKit에 대한 Framework 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  아래 그림에서 중요한 부분은 모델을 Estimator라고 부르고, ***fit/ predict*** 에 대한 기능임!!   \n",
    "* cross_val_score같은 evaluation function,  GridSearchCV와 같은 하이퍼파라미터튜닝에 관련된 것은든 아래의 개별 모델 Estimator를 인자로 받아들이게 된다!!!!!   \n",
    "* 인자로 받은 Estimator 에 대해서 cross_val_score, GridSearchCV.fit() 함수 내에서 Estimator의 fit(), predict()를 호출해서 평가를 하거나 파라미터에 대한 튜닝작업을 수행을 하게 됨!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/03.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비지도학습인 : 차원축소, 클러스터링, Feature Extraction 같은 경우에는 대부분이 ***fit / transform*** 을 적용을 한다.\n",
    "- 이 때의 fit()의 기능은 학습을 의미하는 것이 아니라  ***입력한 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 작업을 수행*** 을 의미하는 거임!!<br>\n",
    "- 그리고 이 떄의 실제 작업은  ***transform***이 수행을 하게 되어서 직접 변환이 이루어지게 됨.<br>\n",
    "- 물론 이 떄의 한 번에 결합을 해서 한 번에 해결하기 위해서  ***fit_transform***을 수행하기도 함. 단, 주의사항이 있기는 함;;;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn 주요 모듈 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/04.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/05.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Model Selection 모듈 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-1) train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기능 : 학습데이터와 테스트 테이터를 분리하는 기능 수행 <br>\n",
    "- test_size : (0.25)전체 데이터 중에서 테스트 테이터를 얼마만큼의 비율로 가져갈지 설정<br>\n",
    "- shuffle : (True) 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정함. 한 쪽으로 몰려있을 수 있기 때문에 랜덤하게 뽑기 전에 이미 한 번 흔들어서 시작을 하기 위해서 설정하는 부분<br>\n",
    "- random_state : 난수 발생 -> 재현성<br>\n",
    "- 출력형태 : X_train, X_test, y_train_ y_test 순서에 유의!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<i class=\"fa fa-question-circle\"></i> 질문:** 학습데이터를 바탕으로 실전문제를 푼 경우 --> 즉, 학습에 미리 시험에 나올 문제를 보고 공부를 한 경우임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도:',accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 미리 나올 문제를 보고 학습을 하였기에 상당히 성능이 높게 나온다!!!\n",
    "이러한 일이 발생을 하면, 내가 데이터를 뭔가 섞어서 한 것이 아닌가 의심을 해야함!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<i class=\"fa fa-question-circle\"></i> 질문:** 이제 미리 시험문제가 뭐가 나올지 모르는 상태에서 공부를 하기 위해서, 모의고사와 실전 문제로 나누자!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> 역시나 미리 뭐가 나올지 모르는 상태에서 공부를 하게 되니 100%하기가 쉽지 않게 된다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<i class=\"fa fa-question-circle\"></i> 질문:**  그러면 random_state를 변경하면 어떻게 될지 알아보자..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9111\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.3, random_state=222)\n",
    "dt_clf = DecisionTreeClassifier( )\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-2)  Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 교차검증 : 앞에서 train_test_split으로 해서해도, 과적합 overfitting의 문제점이 가지고 있음. 즉, 학습에 너무 과하가 최적화가 되어서 새로운 데이터에 성능이 떨어지는 문제점이 존재 <br>\n",
    "    여러번의 모의고사/실전으로 수행을 하는 부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/06.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* k-Fold CV : k 등분해서 하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/07.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<i class=\"fa fa-question-circle\"></i> 질문:** K-Fold에 대해서 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기:',features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환  \n",
    "for train_index, test_index  in kfold.split(features):\n",
    "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측 \n",
    "    dt_clf.fit(X_train , y_train)    \n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    # 반복 시 마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stratified k Fold : 비율을 유지하면서 불균형한 분포에 대해서 나눌 때.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<i class=\"fa fa-question-circle\"></i> 질문:**  우선은 k-Fold에 대해서 해보고, 이를 Stratified k-fold에 대해서 해보기ㅡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 2    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "# kfold.split(X)는 폴드 세트를 3번 반복할 때마다 달라지는 학습/테스트 용 데이터 로우 인덱스 번호 반환. \n",
    "n_iter =0\n",
    "for train_index, test_index  in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train= iris_df['label'].iloc[train_index]\n",
    "    label_test= iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold #비율을 유지하면서 쪼개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# KFold -> 몇 등분\n",
    "# StratifiedKFold -> 무엇을 기준으로, 몇 등분\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']): #iris_label : 기준비율\n",
    "    n_iter += 1\n",
    "    label_train= iris_df['label'].iloc[train_index]\n",
    "    label_test= iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "skfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1234) # shuffle : 데이터를 섞는거\n",
    "\n",
    "# random_state를 하기 위해서는 아래의 경우 처럼 사용..\n",
    "#skfold = StratifiedKFold(~~~)\n",
    "\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFold의 split( ) 호출시 반드시 레이블 데이터 셋도 추가 입력 필요  \n",
    "for train_index, test_index  in skfold.split(features, label):\n",
    "    # split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측 \n",
    "    dt_clf.fit(X_train , y_train)    \n",
    "    pred = dt_clf.predict(X_test)\n",
    "\n",
    "    # 반복 시 마다 정확도 측정 \n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 교차 검증별 정확도 및 평균 정확도 계산 \n",
    "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도:', np.mean(cv_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 참고) 회귀의 경우에는  stratified k-fold를 사용할 필요가 없음;;아니 사용하기 힘들다;;;;어떤 비율로 유지할지에 대한 내용이 없기 때문에;;;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-3) cross_val_score : CV를 보다 편하게.. ->지금까지 모든 과정을 한번에 하기 위함.. \n",
    "           크로스 _ 검증 - 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score -> 분류모델, 문제, 정답, 평가기준, 몇 등분해서 할지<br>\n",
    "모델을 가지고 등분해서 나눠주고, 이에 대해서 fit 하고, predict하고, 평가까지 1번에..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 3개 \n",
    "# cvs : 모델, 문제지, 정답지, 채점기준, 몇등분,,\n",
    "scores = cross_val_score(dt_clf, X= data, y=label,scoring='accuracy', cv=3, n_jobs=-1)\n",
    "print('교차 검증별 정확도:',np.round(scores, 4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) cross_validate()도 존재를 하는데, 이것은 여러가지 평가지표를 사용할 때. scoring에서 여러가지 평가지표를 할 때 사용한다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03-4) gridsearchCV ->케이스가 너무 많으면 시간이 오래걸리니까"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 최적의 파라미터의 조합들에 대해서 알려준다.\n",
    " 직접 모든 조합에 대해서 다 하는 gridsearch, 분포를 보고 적당한 조합들에 대해서 수행을 하는 randomgridsearch 가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습데이타와 테스트 데이터 분리\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier() #모델준비 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### parameter 들을 dictionary 형태로 설정\n",
    "parameters = {\"max_depth\" : [1, 2, 3],\n",
    "              \"min_samples_split\" : [2,3]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# param_grid의 하이퍼 파라미터들을 3개의 train, test set fold 로 나누어서 테스트 수행 설정.  \n",
    "### refit=True 가 default 임. True이면 가장 좋은 파라미터 설정으로 재 학습 시킴.  \n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, n_jobs=-1, refit=True) # refit : 제일 좋은 조합으로,, 수행할 것. \n",
    "\n",
    "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\n",
    "grid_dtree.fit(X_train, y_train) \n",
    "\n",
    "# GridSearchCV 결과 추출하여 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "#전제조건 : .주어진 train데이터를 가지고 최적의 모델을 찾는다. \n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<i class=\"fa fa-question-circle\"></i> 질문:** ScikitLearn에서 모델을 돌리기 전에 처리해야 하는 주의사항<br>\n",
    "결측값 입력이 안 됨;;;-> NaN처리 해야함<br>\n",
    "수치데이터가 아닌 카테고리 변수들을 허용이 안 됨 --> 수치데이터로 변형해야 함<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04-1) 데이터 인코딩 : label encoding / one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding <br> \n",
    "- 장점 : 그냥 카테고리 변수를 알아서 0부터 숫자로 변경해 줌 <br>\n",
    "- 단점 : 숫자로 변경이 되다보니 숫자의 크기가 모델에 반영이 됨. 1보다 3이 더 크게 되고, 그러니 3번인 선풍기가 0번인 TV보다 더 중요하게 인식하게 될 수 있는 가능성이 있음. 우리는 그냥 단순 종류인 것인데, 크기에 대한 부분이 반영이 될 수 있다;;;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후 , fit( ) 과 transform( ) 으로 label 인코딩 수행. \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items) # 냉장고 -> 1, 등의 규칙을  찾아 //특별하게 지정하지 않으면 알파벳 순서대로 \n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값:',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자렌지' '컴퓨터']\n",
      "디코딩 원본 값: ['전자렌지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스:',encoder.classes_)\n",
    "print('디코딩 원본 값:',encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3])) # 숫자 -> 문자로 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/08.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding  : 주의사항 --> 숫자로 라벨인코딩을 하고, 이를 바탕으로 원핫인코딩의 작업을 해야함!!! <br> 한 번에 진행하는 부분이 없다는 점!!!!! ---> 꼭 2 Step!!!!\n",
    "\n",
    "One Hot Encoding : 라벨의 가중치를 없애버리는것!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/09.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items=['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# Step 1) \n",
    "# 먼저 숫자값으로 변환을 위해 LabelEncoder로 변환합니다. \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "\n",
    "# Step 2)\n",
    "labels = encoder.transform(items)\n",
    "# 2차원 데이터로 변환합니다. \n",
    "labels = labels.reshape(-1,1) # 가로로 나타나는 label을 이차원으로 reshape\n",
    "\n",
    "# 원-핫 인코딩을 적용합니다. \n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 참고로 pandas에서는 이를 좀 더 쉽게 하는 부분이 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자렌지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자렌지  item_컴퓨터\n",
       "0        1         0        0         0          0         0\n",
       "1        0         1        0         0          0         0\n",
       "2        0         0        0         0          1         0\n",
       "3        0         0        0         0          0         1\n",
       "4        0         0        0         1          0         0\n",
       "5        0         0        0         1          0         0\n",
       "6        0         0        1         0          0         0\n",
       "7        0         0        1         0          0         0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서'] })\n",
    "pd.get_dummies(df) #onehotencoding 간단하게 해주는 패키지!! ->특정한 컬럼(OneHotEncoding을 하려는)을 선정해서 더미로 던져줘야해!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature Scaling & Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서로 다른 변수의 값의 범위를 일정한 수준으로 맞추는 작업을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반적인 표준호 : 평균0, 분산1인 분포로 변환하는 것을 의미<br>\n",
    "<img src=\"img/10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반적인 정규화 : 서로다른 크기의 값들을 동일한 크기 단위 0~1사이의 값으로 변경<br>\n",
    "<img src=\"img/11.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의!!! scikit learn의 Normalizer의 경우에는 선형대수에서 사용하는 정규화개념을 사용을 함.<br>\n",
    "<img src=\"img/12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 교재에서 용어 정리 : 일반적인 의미의 표준화/정규화를 Feature Scaling으로 이야기를 하고, 선형대수의 정규화를 \"벡터 정규화\"<br>\n",
    "- 대표적인 Feature Scaling : Standard Sclaer, MinMaxScaler에 대해서 알아보겠음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-1) Standard Scaler : 평균0, 분산1으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다. \n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df.var())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature 들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler객체 생성\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.  \n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform( )시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature 들의 평균 값')\n",
    "print(iris_df_scaled.mean()) #---> 모든 컬럼의 평균이 : 0 으로 세팅\n",
    "print('\\nfeature 들의 분산 값')\n",
    "print(iris_df_scaled.var())#---> 모든 컬럼의 분산이 : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05-2) MinMaxScaler : 0~1사이의 값으로...혹시 음수의 값이 있다면 -1~+1의 값으로 변환을 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최소 값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최대 값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출.  \n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature들의 최소 값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature들의 최대 값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주의사항) train과 test의 변환 기준이 동일해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0 부터 10까지, 테스트 데이터는 0 부터 5까지 값을 가지는 데이터 세트로 생성\n",
    "# Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array =  np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# 최소값 0, 최대값 1로 변환하는 MinMaxScaler객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "# fit()하게 되면 train_array 데이터의 최소값이 0, 최대값이 10으로 설정.  \n",
    "scaler.fit(train_array)\n",
    "# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n",
    "train_scaled = scaler.transform(train_array)\n",
    " \n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# 앞에서 생성한 MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최소값이 0, 최대값이 5으로 설정됨 \n",
    "scaler.fit(test_array)\n",
    "# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.  \n",
    "test_scaled = scaler.transform(test_array)\n",
    "# train_array 변환 출력\n",
    "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# read_csv  로 데이터 불러오기..\n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### train 데이터 정보 ###  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\n ### train 데이터 정보 ###  \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 Null 값 갯수  0\n"
     ]
    }
   ],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "print('데이터 세트 Null 값 갯수 ',titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sex 값 분포 :\n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin 값 분포 :\n",
      " N              687\n",
      "G6               4\n",
      "C23 C25 C27      4\n",
      "B96 B98          4\n",
      "F2               3\n",
      "              ... \n",
      "A19              1\n",
      "C101             1\n",
      "B102             1\n",
      "B69              1\n",
      "C70              1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 :\n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(' Sex 값 분포 :\\n',titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin 값 분포 :\\n',titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 :\\n',titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 앞 글자 1개 추출\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].apply(lambda x : x[0]) #titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupby 이용해서,,,아래와 같이 표현... count 를 활용...\n",
    "titanic_df.groupby(['Sex','Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x266613a5508>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 아래와 같은 성별에 따른 생존율 그래프..\n",
    "sns.barplot(x='Sex', y = 'Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26661b95388>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 아래와 같은 객실등급별 그래프..\n",
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAF0CAYAAABrBu7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhcdZ3v8fc3CUkQgguJRAgxUQJiAMUEVNAh7ODcyzIyAuK+ZNzgclG43BEQcMPgHQUFJTMq4iC7OJFBYYCwIyQBJAkIhkVIoJUEgQADJOF7/zinQ6VTne6GPn2qu9+v5+mnq06d5Vuntk/9fr86JzITSZIk9a0hdRcgSZI0GBnCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmowrO4Cemr06NE5YcKEusuQJEnq0rx585Zm5phmt/W7EDZhwgTmzp1bdxmSJEldiog/d3ab3ZGSJEk1MIRJkiTVwBAmSZJUA0OYJElSDQxhkiRJNTCESZIk1cAQJkmSVANDmCRJUg0MYZIkSTUwhEmSJNWgshAWET+NiL9GxIJObo+IOD0iFkXEXRHxrqpqkSRJajVVtoSdDeyzjtv3BSaVf9OBH1VYiyRJUkupLIRl5vXAE+uYZX/gnCz8HnhdRLypqnokSZJaybAat70Z8EjD9cXltMc6zhgR0ylayxg/fnyfFCdJkvqnh0/etk+3N/6E+a9ouToH5keTadlsxsycmZlTM3PqmDFjKi5LkiSpenWGsMXA5g3XxwGP1lSLJElSn6ozhM0CPlb+SvI9wFOZuVZXpCRJ0kBU2ZiwiDgPmAaMjojFwNeA9QAy88fA5cAHgEXAc8Anq6pFkiSp1VQWwjLz0C5uT+CLVW1fkiSplXnEfEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqsGwuguQAI455hja2toYO3YsM2bMqLscSZIqZwhTS2hra2PJkiV1lyFJUp+xO1KSJKkGhjBJkqQaGMIkSZJq4JgwSf2KP+KQNFAYwiT1K/6IQ9JAYXekJElSDQxhkiRJNTCESZIk1cAQJkmSVAMH5kvSAOCvRqX+xxAmSQOAvxqV+h+7IyVJkmpgCJMkSaqB3ZGSJA0ijh9sHYYwSZIGEccPtg67IyVJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBh4nTE15MD9JkqplCFNTHsxP0kDgF0q1MkOYJGnA8gulWpljwiRJkmpgCJMkSaqBIUySJKkGlYawiNgnIu6NiEURcWyT28dHxOyIuCMi7oqID1RZjyRJUquoLIRFxFDgDGBf4O3AoRHx9g6zHQdcmJnbA4cAZ1ZVjyRJUiupsiVsR2BRZj6QmS8C5wP7d5gngY3Ky68FHq2wHkmSpJZRZQjbDHik4friclqjE4GPRMRi4HLg8GYriojpETE3IuY+/vjjVdQqSZLUp6oMYdFkWna4fihwdmaOAz4A/CIi1qopM2dm5tTMnDpmzJgKSpUkSepbVYawxcDmDdfHsXZ346eBCwEy8xZgJDC6wpokSZJaQpUhbA4wKSImRsRwioH3szrM8zCwO0BEbE0RwuxvlCRJA15lISwzVwJfAq4A7qH4FeTCiDg5IvYrZ/sy8NmI+ANwHvCJzOzYZSlJkjTgVHruyMy8nGLAfeO0Exou3w3sXGUNkiRJrcgj5kuSJNXAECZJklQDQ5gkSVINKh0TJkmSqvPwydv2eJmVT7wBGMbKJ/7c4+XHnzC/x9tT52wJkyRJqoEhTJIkqQZ2R6rX2TwuSVLXDGGS1GL8IiMNDnZHSpIk1cAQJkmSVAO7IyXVxm43SYOZIUyS1C8Y2jXQ2B0pSZJUA0OYJElSDQxhkiRJNTCESZIk1cAQJkmSVANDmCRJUg0MYZIkSTUwhEmSJNXAg7VKPXDMMcfQ1tbG2LFjmTFjRt3lSJL6MUOY1ANtbW0sWbKk7jIkSQOA3ZGSJEk1MIRJkiTVwBAmSZJUA0OYJElSDQxhkiRJNTCESZIk1cAQJkmSVANDmCRJUg0MYZIkSTUwhEmSJNXAECZJklQDQ5gkSVINDGGSJEk1GFZ3AZIkqe+MHvkSsLL8rzoZwiRJGkS+st2TdZegkt2RkiRJNbAlTJI0YNn1plZmCJMkDVh2vamVGcIGgSlHn9PjZUYtXc5Q4OGly3u8/KWjerw5SZIGHceESZIk1cAQJkmSVAO7IyVpAHAAutT/GMIkaQBwALrU/9gdKUmSVANDmCRJUg0MYZIkSTUwhEmSJNXAECZJklQDQ5gkSVINDGGSJEk1MIRJkiTVoNIQFhH7RMS9EbEoIo7tZJ4PRcTdEbEwIn5ZZT2SJEmtorIj5kfEUOAMYE9gMTAnImZl5t0N80wC/i+wc2b+LSLeWFU9kiRJraTKlrAdgUWZ+UBmvgicD+zfYZ7PAmdk5t8AMvOvFdYjSZLUMqo8d+RmwCMN1xcD7+4wz5YAEXETMBQ4MTN/V2FNkiTpVVqxYgWLFy/m+eefr7uUplbu+f0+3d4999zDyJEjGTduHOutt163l6syhEWTadlk+5OAacA44IaI2CYz1zgTbURMB6YDjB8/vvcrlSRJ3bZ48WJGjRrFhAkTiGj2cV+vFx59qU+3N/xNb2PZsmUsXryYiRMndnu5KrsjFwObN1wfBzzaZJ7/yMwVmfkgcC9FKFtDZs7MzKmZOXXMmDGVFSxJkrr2/PPPs/HGG7dkAKtDRLDxxhv3uGWwyhA2B5gUERMjYjhwCDCrwzy/BnYFiIjRFN2TD1RYkyRJ6gUGsDW9kv1RWQjLzJXAl4ArgHuACzNzYUScHBH7lbNdASyLiLuB2cDRmbmsqpokSVL/8s1vfpPJkyez3Xbb8c53vpNbb7217pJ6zTrHhEXEctYex7VaZm60ruUz83Lg8g7TTmi4nMBR5Z8kSdJqt9xyC5dddhm33347I0aMYOnSpbz44ot1l9Vr1tkSlpmjyqD1feBYil88jgP+D/CN6suTJEmD1WOPPcbo0aMZMWIEAKNHj2bTTTdl3rx57LLLLkyZMoW9996bxx57jJUrV7LDDjtw7bXXAnDct7/HCaecVmP1Xetud+TemXlmZi7PzKcz80fAB6ssTJKaGT3yJTZZfyWjR/btr58k9b299tqLRx55hC233JIvfOELXHfddaxYsYLDDz+ciy++mHnz5vGpT32Kr371qwwbNoyzzz6bz3/+81x1/c381+ybOO6oL9R9F9apu4eoWBURh1EccDWBQ4FVlVUlSZ34ynZPdj2TpAFhww03ZN68edxwww3Mnj2bgw8+mOOOO44FCxaw5557ArBq1Sre9KY3ATB58mQ++tGP8sFPfInrZp3L8OHdP2ZXHbobwj4MnFb+JXBTOU2SJKkyQ4cOZdq0aUybNo1tt92WM844g8mTJ3PLLbc0nX/+/Pm8bqNR/PXx1v+dX7e6IzPzoczcPzNHZ+aYzDwgMx+quDYNInYxSZI6uvfee/nTn/60+vqdd97J1ltvzeOPP746hK1YsYKFCxcC8Ktf/Yply5Zx1SU/56jjv82TTz1dS93d1a2WsIjYEvgRsElmbhMR2wH7ZaaD89Ur7GKSJHX0zDPPcPjhh/Pkk08ybNgwtthiC2bOnMn06dM54ogjeOqpp1i5ciVHHnkkm2yyCcceeyxXX301bxz6NJ//5KF8+YRT+Mlp36r7bnSqu92R/wocDZwFkJl3RcQv8ReSkiSpIlOmTOHmm29ea/ro0aO5/vrr15p+3333AfDCowv54qc/Unl9r1Z3fx35msy8rcO0lb1djCRJ0mDR3RC2NCLeSnng1og4CHissqokSZIGuO52R34RmAm8LSKWAA8Ch1VWlSRJ0gDX3RD258zcIyI2AIZk5vIqi5IExxxzDG1tbYwdO5YZM2bUXY4kqZd1N4Q9GBG/Ay4ArqmwHkmltrY2lixZUncZkqSKdHdM2FbAVRTdkg9GxA8j4n3VlSVJkjSwdfdgrf+dmRdm5j8A2wMbAddVWpkkSVIvu+7m2zjwY61xTsnudkcSEbsABwP7AnOAD1VVlCRJ6j+mHH1Or65v3qkf69X1taputYRFxIPAkcANwDaZ+aHMvKTSyiRJkpp46KGHeNvb3sZnPvMZttlmGw477DCuuuoqdt55ZyZNmsScO+Yz5475TNvvMN6910FM2+8w7lv04Frrefa555h+1HHs/IGDefdeB/GbK/p22Ht3W8LekZmtfQImSZI0aCxatIiLLrqImTNnssMOO/DLX/6SG2+8kVmzZjHjB6fzk9O+xVW/+jnDhg3j6utv4YTvnMb5//r9NdZxymkzmbbzu5n5L9/gyaee5n1/fyi7vf89bPCa1/TJfVhnCIuIYzJzBvDNiMiOt2fmEZVVJkmS1ImJEyey7bbbAjB58mR23313IoJtt92WPz+yhKeeXs5njvxnFj34MBHBihVrn+jn6utv5j//61q+/+OzAXj+hRd4ZMljvG3SW/vkPnTVEnZP+X9u1YVIkiR114gRI1ZfHjJkyOrrQ4YMYeWqVZx06g/ZZacdufAnp/PQI0vY66BPrrWOTDh/5vfYcouJfVZ3o3WOCcvM35QX78rMn3f864P6JEmSeuzp5cvZdOwmAPziwl83nWePXXbizJ/9ksyis+/OBfc0na8q3T1O2L9ExB8j4usRMbnSiiRJkl6loz7/KY7/9veZtv9HWLXqpabz/PORn2PFipVM3eMfeNduB3DSjB/0aY3dGpifmbtGxFiKw1LMjIiNgAsy8xuVVidJklpeXx9SYsKECSxYsGD19bPPPnuN226/pmj5WnDjf66efuIxhwOwy047sstOOwKw/vojOWPG1/qg4ua62xJGZrZl5unA54A7gRMqq0qSJGmA6+5xwraOiBMjYgHwQ+BmYFyllUmSJA1g3T1O2M+A84C9MvPRCuuRJEkaFLoMYRExFLg/M0/rg3okSZIGhS67IzNzFbBxRAzvg3okSZIGhe52R/4ZuCkiZgHPtk/MzH+ppCpJkqQBrru/jnwUuKycf1TDnyRJUp87/fTT2XrrrTnssMMqWf/X/98ZfO/HP6tk3e26e5ywkyqtQpIk9VsPn7xtr65v/Anzu5znzDPP5Le//S0TJ9ZzyqHe0K0QFhGzgWYn8N6t1yuSJElah8997nM88MAD7LfffhxyyCHcf//9zJ8/n5UrV3LiiSeyzw5bcM4Fv+Y3V1zDqlWrWHjvIo78p4/z4osr+OUlv2HE8OH8+hc/4g2vfy0/OfdifnruRbz44greOnE8Pz3927xm/fXX2N79Dz3MkV/9JkuX/Y311x/Jj049ka22eMurvh/d7Y78CnB0+Xc8xcFaPam3JEnqcz/+8Y/ZdNNNmT17Ns8++yy77bYbc+bMYfbs2Rx99NE8+9xzACy890/8/IwZ3Pif5/G175zOa9Yfya1XXsy7p7yDcy+eBcAB++7BTZdfwJyrfsVWW7yFs8/71Vrb++IxJ/G9r/8zt/zuQk45/isc8X9754RB3e2OnNdh0k0RcV2vVCBJkvQKXXnllcyaNYvvfve7ADz//PM8suQxoDhF0agNN2DUhhuw0agN+cCe0wCYvPUkFtx9H1AEtRNn/ICnnl7OM88+x5677LTG+p959jl+P+9OPvxPR62e9sKLL/ZK7d3tjnxDw9UhwFRgbK9UoJb00vAN1vgvSVIrykwuueQSttpqq9XTXnh0IbfdPp8Rw18+utaQIUMYMaK4PiSGsHLVKgA++7+P46KfnMZ2k9/GORf8mutvmbPG+l966SVet9EobvuvS3q99u52R86j6H6cS3HKoqOAT/d6NWoZz07ai+WTD+TZSXvVXYokSZ3ae++9+cEPfkBmMXT9jjvu6NHyzzzzLGM3GcOKFSs4/9LL1rp9o1EbMmHzzbjkN1cARei7a+EfX33hdBHCImKHiBibmRMz8y3AScAfy7+7e6UCSZKkV+j4449nxYoVbLfddmyzzTYcf/zxPVr+a0d/iff/jw/zgUM/2+lg+5/98Ducff6v2GGPf2D7XffnN1fO7o3Su+yOPAvYAyAi/g74NnA48E5gJnBQr1QhSZL6re4cUqK3PfTQQ6svn3XWWWvc9sKjC/nYwQfwsYMPWD3tvluvXH258bbpHz+E6R8/ZK31H//lL66+PHH8OH5z7llrzfNqdRXChmbmE+Xlg4GZmXkJcElE3Nnr1UiSJA0SXY0JGxoR7UFtd+Cahtu6e8ojSZIkddBVkDoPuC4ilgL/DdwAEBFbAE9VXJskSdKAtc4QlpnfjIirgTcBV2b7Tw+KFrTDqy5OkiS1pswkIuouo2W8HJG6r8suxcz8fZNp9/V4S5IkaUAYOXIky5YtY+ONNzaIUQSwZcuWMXLkyB4t57guSZLUI+PGjWPx4sU8/vjjdZfS1Mon2/p0e8OeGsLIkSMZN25cz5arqB5JkjRArbfeekycOLHuMjr18Mkf6tPtvdJDdHT3iPmSJEnqRYYwSZKkGhjCJEmSamAIkyRJqoED8zVoTTn6nB4vM2rpcoYCDy9d3qPl5536sR5vS5I0sNkSJkmSVANDmCRJUg0MYZIkSTUwhEmSJNWg0hAWEftExL0RsSgijl3HfAdFREbE1CrrkSRJahWVhbCIGAqcAewLvB04NCLe3mS+UcARwK1V1SJJktRqqmwJ2xFYlJkPZOaLwPnA/k3m+zowA3i+wlokSZJaSpUhbDPgkYbri8tpq0XE9sDmmXlZhXVIkiS1nCpDWDSZlqtvjBgCfA/4cpcripgeEXMjYu7jjz/eiyVKkiTVo8oQthjYvOH6OODRhuujgG2AayPiIeA9wKxmg/Mzc2ZmTs3MqWPGjKmwZEmSpL5RZQibA0yKiIkRMRw4BJjVfmNmPpWZozNzQmZOAH4P7JeZcyusSZIkqSVUFsIycyXwJeAK4B7gwsxcGBEnR8R+VW1XkiSpP6j0BN6ZeTlweYdpJ3Qy77Qqa5EkSWolHjFfkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaDKu7AGkwePjkbXu8zMon3gAMY+UTf+7x8uNPmN/j7UmS+pYtYZIkSTWwJUySpJodc8wxtLW1MXbsWGbMmFF3OS1hMOwTQ5gkSTVra2tjyZIldZfRUgbDPrE7UpIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBh4xX5LUZwbDqWik7jKESZL6zGA4FY3UXXZHSpIk1cAQJkmSVANDmCRJUg0MYZIkSTWoNIRFxD4RcW9ELIqIY5vcflRE3B0Rd0XE1RHx5irrkV6tl4ZvwKoRG/HS8A3qLkWS1M9V9uvIiBgKnAHsCSwG5kTErMy8u2G2O4CpmflcRHwemAEcXFVN0qv17KS96i6h5XjIAUl6ZapsCdsRWJSZD2Tmi8D5wP6NM2Tm7Mx8rrz6e2BchfVIqkD7IQfa2trqLkWS+pUqQ9hmwCMN1xeX0zrzaeC3FdYjSZLUMqo8WGs0mZZNZ4z4CDAV2KWT26cD0wHGjx/fW/VJkiTVpsqWsMXA5g3XxwGPdpwpIvYAvgrsl5kvNFtRZs7MzKmZOXXMmDGVFCtJktSXqmwJmwNMioiJwBLgEODDjTNExPbAWcA+mfnXCmuRJKlPTDn6nB4vM2rpcoYCDy9d3qPlLx3V402phVQWwjJzZUR8CbgCGAr8NDMXRsTJwNzMnAWcCmwIXBQRAA9n5n5V1SRJfcVfjUrqSqUn8M7My4HLO0w7oeHyHlVuX5Lq4omqJXXFI+ZLkiTVoNKWMEnSwNWXY5/A8U8aeGwJkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEhTJIkqQbD6i5AkjR4vDR8gzX+S4OZIUyS1GeenbRX3SVILcMQJklSzWwhHJwMYZIk1cwWwsHJECZJXZhy9Dk9XmbU0uUMBR5eurzHy186qsebk9QP+etISZKkGhjCJEmSamAIkyRJqoFjwiRJUqUcV9mcLWGSJEk1MIRJkiTVwBAmSZJUA0OYJElSDRyYL2k1B89KUt+xJUySJKkGhjBJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEHa5WkCrw0fIM1/ktSR4YwSarAs5P2qrsESS3O7khJkqQaGMIkSZJqYAiTJEmqgSFMkiSpBoYwSZKkGhjCJEmSamAIkyRJqoEhTJIkqQaGMEmSpBoYwiRJkmpgCJMkSaqBIUySJKkGhjBJkqQaVBrCImKfiLg3IhZFxLFNbh8REReUt98aEROqrEeSJKlVVBbCImIocAawL/B24NCIeHuH2T4N/C0ztwC+B3ynqnokSZJaSZUtYTsCizLzgcx8ETgf2L/DPPsDPy8vXwzsHhFRYU2SJEktocoQthnwSMP1xeW0pvNk5krgKWDjCmuSJElqCZGZ1aw44h+BvTPzM+X1jwI7ZubhDfMsLOdZXF6/v5xnWYd1TQeml1e3Au6tpOieGw0srbuIFuR+WZv7pDn3S3Pul+bcL2tznzTXSvvlzZk5ptkNwyrc6GJg84br44BHO5lncUQMA14LPNFxRZk5E5hZUZ2vWETMzcypddfRatwva3OfNOd+ac790pz7ZW3uk+b6y36psjtyDjApIiZGxHDgEGBWh3lmAR8vLx8EXJNVNc1JkiS1kMpawjJzZUR8CbgCGAr8NDMXRsTJwNzMnAX8BPhFRCyiaAE7pKp6JEmSWkmV3ZFk5uXA5R2mndBw+XngH6usoWIt10XaItwva3OfNOd+ac790pz7ZW3uk+b6xX6pbGC+JEmSOudpiyRJkmowKEJYREyIiAUdpp0YEV9ZxzKfiIgfVl9d64uIVRFxZ0T8ISJuj4iduph/rf09EEXE2Ig4PyLuj4i7I+LyiJgeEZd1Mv+/tZ81IiIeiojRTeZZ5/Oyr0XExuVjf2dEtEXEkobrw+uur9VExFcjYmFE3FXuo3dHxJER8ZpXsK5nXkUdn4iITV/p8l2sOyLixojYt2HahyLid1Vsrxv1bBIRKyPi0+uY5zMR8f0u1rNFRNxZXn5XROzT27V2V0QcGBEZEW/r5PazI+KgLtax+jMsIg5ocsaaltbwudP+d2w5/dqIWOtXj6/kMzsipnX2ft1XKh0TpgHjvzPznQARsTfwbWCXekuqV3lmh0uBn2fmIeW0dwL/s7Nl2o+Z15+Ux+xrf+xPBJ7JzO/WWlQ3RcSw8iDQfbW99wL/A3hXZr5QhuzhwAXAvwPP9VUtwCeABax9WKBXLTMzIj4HXBQRsyl+ePVNoK7QcjBwC3AoxY+9esO7gG2AWoIlxX25keLHaif2wvoOAC4D7u6FdfWV1Z87VSgPi1W7QdESti5lqv5ORNwWEfdFxPubzPP3EXFLRIwuv4GcHhE3R8QD7d9Gym+Hp0bEgoiYHxEHl9PPjIj9ysuXRsRPy8ufjohvlK1G90TEv5bfoK+MiPX7ch/00EbA3wAiYsOIuLpsHZsfEY2npRoWET8vWwQujojXRMTuEXFp+wwRsWdE/Kqv70Av2RVYkZk/bp+QmXcCNwAblvf5jxFxbhnY1vUN7qtRnOj+KoqDEfcLEfHx8nVzZ/k8H1JO37d8vdweERdExAbl9MVRtPTdUT4vtiynv6ec/46IuCkiJpXTN4iIS6JogT0vIuaWQberbRwfETcBB/bxLnkTsDQzXwDIzKUUh97ZFJhdBpY1Wrgi4qCIOLu8PLG8T3Mi4uuNK46Io8vpd0XESeW0pu8d5XvSVODc8rHp9feTzFwA/Ab4P8DXgHMy8/6IOKZ8D1wQEYeXda5uYSqvHxsRx5WXb4yIU8rn0b1RtrKv67Fv4lDgSOAtETG2YTufieI9/VrgPQ3T/z0iDmi4vkaLY7m/TgAOK/ffOluceltEbAjsTHFu5fYveBERP4yixf0/gTc2zL+6VT0ippb3t3F9OwH7AaeW9+etfXRXKhcRnywf4+so9ln79DHl82dO+bdzOf3EiJgZEVcC5zTMPyQi/hQRYxquL4omvRW9bdCHsNKwzNyR4oX8tcYbIuJA4FjgA+WbKhRvtu+j+NZ7SjntHyhaDN4B7EHxhH8TcD3QHuw2oziZOeXyN5SXJwFnZOZk4Engg71671699csX7x+BfwPaPyCeBw7MzHdRhJL/F7H63J9bATMzczvgaeALwDXA1u1PdOCTwM/66k70sm2AeZ3ctj3Fc+ntwFtoeHPoKCKmULzRbk/xHNqhd8usRkRsQxFydiq/rQ4DDomIN1K8XnYvnxd3Af+rYdG/ZOb2FM+jo8pp9wDvK6d/HfhGOf1woC0z30HxOtu+3HZX23g2M3fOzIt6+3534Upg8/JD4cyI2CUzT6dojdo1M3ftYvnTgB9l5g5AW/vEiNiL4j1iR4r3mCkR8XflzWu9d2TmxcBc4LDMfGdm/ndv3skGJwEfBvYFZkTEjsBhZZ3vBb4QEdt1Yz1Rvv8eTRF+oJPHfq0FIyYAr8/MeRTnH/5QOX0ccHxZx14Ur9duKffXycC55f67uLvL9pIDgN9l5n3AExHxLorX2lbAtsBngXUOCWmUmTdTHJPz6PL+3F9BzVVo/9xp/zu48cby8/UkivfXPa3Zjx0AAAinSURBVHn5sxWK19L3ytfSByneb9pNAfbPzA+3T8jMlyhaqw8rJ+0B/KHhM78yLdEc1wc6+wlo+/T21ph5wISG23el+Ea5V2Y+3TD91+WDdndEbFJOex9wXmauAv5SJvMdKILWkVH0x98NvL588rwXOILiXJkPlq0ozWpoBY3dke8Fzik/hAP4VvmB8BJFyGzfH49k5k3l5X8HjsjM70bEL4CPRMTPKPbBx/ryjvSR2xpOxXUnxeN5Yyfzvh+4NDOfK+fveEDjVrUHxfN7bpm716c4D+xzFG+GN5fTh7PmfW98rX2gvPw6iudUx2/o7wO+A5CZf4jiNGdQfACtaxsXvMr79opk5jNlqH4/xXvHBVGOY+mmnXn5C9gvKO87RYjYC7ijvL4hRfh6mBrfOzLz2Yi4gKKL+oUoehEuaXgu/5riMbyyi1U1e//t7LHv6FBefrzPB84ATqdo+bq6/RR4EXEhML5n97A2hwLt49fOL6+vx8ufL49GxDV1FdeHuuqOfDdwbWY+DlA+F7csb9sDePvLbQJsFBGjysuzOvli8lPgPyj2/afoowaCwRLClgGv7zDtDcCD5eUXyv+rWHOfPEDRkrElxTdLOswPRRBp/L+GzFwSEa+nGC9xfbndD1G8cS2PiI07rG8VxQdaS8rMW8om2jEUH6JjgCmZuSIiHgJGts/acdHy/88oujGeBy7qyzE7vWwhRVdTMx0fz65eZ/3xODFBcQDm49eYWLQc/y4zP9rJcs1ea98ErsjMMyNiC14eh9P0NVVOX9c2nu3OHahC+SF5LXBtRMzn5TOCrDFbw+WR67itXQDfzsyz1phYtALV/d7xUvkHnT9eK1mz12VkOa1ds+dEZ+vq6FBg44ho38+bRsTE8nJnr6vV9UTEUFroc7D8PNgN2CYikmK8XVKMP+3y/rD282mg62yfDAHe2zFslaGs6ftDZj4SEX+JiN0oAt5hzebrbYOiOzIznwEei4jdASLiDRShqLPWiXZ/pugiOiciJncx7/XAwRExtOxu+zvgtvK2Wyi6p66naBn7Ci93RfYrUfxaZyhFsH0t8NcygO0KvLlh1vFlqxm8PMiUzHyUonvmOODsvqq7AtcAIyLis+0TImIHev6DheuBA6MYyzOKdQzsbzFXAR9qGIuycUSMB24GdomIt5TTN4hyjNc6vBZYUl7+RMP0G3m5e2lbXu5ueCXbqFxEbNWhjndSvIcsB0Y1TP9LRGwdxRi6xnFrN/HyWUMaPwCuAD5VjhUiIjYru2TXpeM2+0Ljc3lDYH+K97k2inD0+ogYCfx9N9bV2WO/Wtm7MDQzN8vMCZk5ATiVYh/+Htg9It4Qxa94G78wPUTRJQXF/h/aZPt17D8o6jwnM99c3qfNKRoLnqDo7h9a9qQ0dm0/xMv3p7OhLHXdnyrdCkwr33vWY80Dv18JfKn9SnQ+nrCjf6Poubmw/EJVuUERwkofA44ru4euAU7qTt94Zt5L8YZ4UZPukkaXUoxN+UO5/mMys31cxw0U484WAbdTtIb1pxC2um+eoun/4+UT9FxgakTMpdhHf2xY5h7g4xFxF8X9/VHDbedSdFf2p1/qrKE8x+mBwJ5RHKJiIcWvmHr0a7TMvJ1in94JXEI/eV5k5nyK8RhXlY/xlcAmmfkXigHFF0TEHygC05adrwkoup1OjWIwfaMfAJuV6/8yxa/9nnqF2+gLGwI/j2Lw9F0UweFEiiN3/zbKgfkU49kuo3ifeKxh+f8FfDEi5lAEUwAy80rgl8AtZevaxXT9gXo28OOoaGB+M5l5G3AexXmDf08xvm1+eWaUb5XTZ9G9X+g1few7zPNhivfdRpcAHy6HA3yjrONK1uzJOIvidXsbRVB+gbVdA7wjih+L9OXA/ENpfp/GAn8C5lO8l17XcPtJwGkRcQNFa2Iz5wNHl/envwzM7zgm7JTGGzPzMYrX1y0UXwpvb7j5CIrPprsi4m7gc93c5iyK13GfjVX2iPnqc1Ecy+WOzOytn5NrAIriJ+TDMvP5soXpSmBSP+7CVjf52KsOUfx6/XuZudZREqrSMn3hGhwiYh5Fn/yX665FLW9D4OryAzmAf/JDeNDwsVefKn9E83n6aCzY6u3aEiZJktT3BtOYMEmSpJZhCJMkSaqBIUySJKkGhjBJkqQaGMIk9WsRcWBEZHkg4bpqeF1EfKGu7Uvqnwxhkvq79jMyHNLVjBV6HcVJ6iWp2wxhkvqt8vQ4O1McQf+QctqQiDgzIhZGxGURcXn7Uc8jYkpEXBcR8yLiivIUMJ2te4uIuCoi/hARt0fEWyNiw4i4urw+PyL2L2c/BXhreWTvUyu+25IGCA/WKqk/O4DiZN73RcQTEfEu4C3ABGBb4I0Up9D6aXl+uR8A+2fm4xFxMMXJwz/VybrPBU7JzEvLcx4OAV4EDszMp8vzZv4+ImZRnIpom8zs7jnqJMkQJqlfOxT4fnn5/PL6esBFmfkS0NZwzsatgG2A/4oIKE7c/BhNlCdT3ywzLwUoz39IGeS+FRF/B7wEbAZsUsH9kjQIGMIk9UsRsTGwG7BNRCRFqErWPgHy6kWAhZn53u6svpPphwFjgCmZuSIiHgJG9qhwSSo5JkxSf3UQcE5mvjkzJ2Tm5sCDwFLgg+XYsE2AaeX89wJjIuK9ULRqRcTkZivOzKeBxRFxQDnviIh4DfBa4K9lANsVeHO5yHJgVDV3U9JAZQiT1F8dytqtXpcAmwKLgQXAWcCtwFOZ+SJFcPtORPwBuBPYaR3r/yhwRETcBdwMjKUYJzY1IuZStIr9ESAzlwE3RcQCB+ZL6i5P4C1pwImIDTPzmbLL8jZg58xsq7suSWrkmDBJA9FlEfE6YDjwdQOYpFZkS5ikQS0izqA41lij0zLzZ3XUI2nwMIRJkiTVwIH5kiRJNTCESZIk1cAQJkmSVANDmCRJUg0MYZIkSTX4/16tesLlS1HXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력 age에 따라 구분값을 반환하는 함수 설정. DataFrame의 apply lambda식에 사용. \n",
    "def get_category(age):\n",
    "    if age =='' :\n",
    "        cat = 'Unknown'\n",
    "    elif age<=5 :\n",
    "        cat =\"Baby\"\n",
    "    elif age <= 12 :\n",
    "        cat ='Child'\n",
    "    elif age <=18 :\n",
    "        cat ='Teenager'\n",
    "    elif age <=25 :\n",
    "        cat = 'Student'\n",
    "    elif age <=35 :\n",
    "        cat ='Young Adult'\n",
    "    elif age <=60 :\n",
    "        cat = 'Adult'\n",
    "    else : \n",
    "        cat = 'Elderly'\n",
    "    return cat\n",
    "\n",
    "# 막대그래프의 크기 figure를 더 크게 설정 \n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#X축의 값을 순차적으로 표시하기 위한 설정 \n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "# lambda 식에 위에서 생성한 get_category( ) 함수를 반환값으로 지정. \n",
    "# get_category(X)는 입력값으로 'Age' 컬럼값을 받아서 해당하는 cat 반환\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y = 'Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    # 카테고리 변수들의 컬럼들을 만들고, 이것들을 일관되게 인코딩\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Sex       891 non-null    int32  \n",
      " 2   Age       891 non-null    float64\n",
      " 3   SibSp     891 non-null    int64  \n",
      " 4   Parch     891 non-null    int64  \n",
      " 5   Fare      891 non-null    float64\n",
      " 6   Cabin     891 non-null    int32  \n",
      " 7   Embarked  891 non-null    int32  \n",
      "dtypes: float64(2), int32(3), int64(3)\n",
      "memory usage: 45.4 KB\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출. \n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived'] #정답지.\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test 나누기!! : train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \n",
    "                                                  stratify= y_titanic_df,#비율을 유지해주세요.\n",
    "                                                  test_size=0.2, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비율이 5:3이니까 test/train도 이렇게 나누는게 좋타 \n",
    "y_titanic_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.659218\n",
       "1    0.340782\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0이 몰려있어 \n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616573\n",
       "1    0.383427\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True) #비율유지 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도: 0.7933\n",
      "RandomForestClassifier 정확도:0.8268\n",
      "LogisticRegression 정확도: 0.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acorn-511\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 위 : 분류모델, 아래 : 평가모델 \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# DecisionTreeClassifier 학습/예측/평가\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticRegression 학습/예측/평가\n",
    "lr_clf.fit(X_train , y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7542\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
    "# exec_kfold 호출\n",
    "exec_kfold(dt_clf , folds=5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7902\n",
      "교차 검증 1 정확도: 0.6713\n",
      "교차 검증 2 정확도: 0.8028\n",
      "교차 검증 3 정확도: 0.7887\n",
      "교차 검증 4 정확도: 0.7676\n",
      "평균 정확도: 0.7641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# 몇 등분 -> 각기 시행해서 학습 --> 평가...\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_train, y_train, cv=5, scoring='accuracy',\n",
    "                         \n",
    "                         n_jobs=-1)\n",
    "for iter_count,accuracy in enumerate(scores):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터 : {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.8020\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8380\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # 성능을 높혀보자!\n",
    "\n",
    "parameters = { # x_train에서 cV로 돌려가면서 parameters를 적용, 36개의 랜덤을 뽑아서 테스트 해보자 \n",
    "    'max_depth' : [2,3,5,10],\n",
    "    'min_samples_split' : [2,3,5],\n",
    "    'min_samples_leaf' : [1,5,8]\n",
    "}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, cv=5, scoring='accuracy')\n",
    "grid_dclf.fit(X_train, y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_ # 최적의 모델 선정\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
