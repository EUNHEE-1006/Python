tensorflow(기업)
pytcrch(학계) =>딥러닝을 위한 플랫폼
ML=샘플(관측수), 피쳐, 클래스라벨(타겟) 
값은 반드시 숫자여야 가능해, => 인코딩으로 {0,1}로 수렴해야
train/test => 여러케이스에 대해서 검증하기 위해서 
딥러닝 - 이미지, 소리, 언어 분야에 잘 활용된다. 모든 분야에서 다 잘 돌아가는게 아니다. 특성에 따라 다르다. 
	데이터가 무엇인지, 목적이 무엇인지 고찰하는게 중요
	데이터 수가 많아야 성능이 좋타!!
cross validataion => 모델의 안정석 확보, 오버피팅 없애기, 모델을 여러번 돌려 학습시키는 것
		  데이터 비대칭 문제가 생길 수 있음. 

grid search : 하라는 대로 다 공부해
random grid search : 요령껏 공부해 


회귀++++++
머신러닝의 관점 : 실제값과 기대되는 값의 크로스 펑션 의 차이를 줄이는 것

y=a + B1X1 + B2X2 =>베타 두개를 다 가져가는게 좋을까?
 
	라쏘의 장점은 변수를 죽여서 공선선을 확 줄여  = 급한 애
	릿지는 죽이진 않아도 변수의 영향력을 확 줄여  = 신중한 애
	엘라스틱은 각 장점들 흡수해서 요령껏 사용하겠다. 
	
	(y-y)^2의 차이를 가장 줄이는게 중요해. 거기에 제약조건(라쏘...)을 붙히는 거야. => bias는 좀 커지더라도 variance는 안정적이게 하는거

 
Gradient Descent :  모델에 적합한 기울기와 y절편을 어떻게 찾을 것이냐. 
학습이 잘 되었다. ->모델일 잘 피팅되었다. ->평가기준 (선형회귀 : MSE, MAE = cost function이라 하고, 이를 최소화 하는 것이 핵심)
평가기준을 바탕으로 y절편과 기울기를 찾으면 돼 (값을 최소화 하는 방향으로....)
step size는 미분한값(기울기)*learning rate 곱해서 계산할 간격을 찾아 


GBM : y값 중심으로 대표값을 먼저 찾는다 (=starting point)
	대표값을 기준으로 y값과 비교해서 오차 만들기
	이후 타겟(y값)이 바뀐다. 오차로..
	오차를 줄일 수 있는 트리모델을 지속적으로 만들어 간다. 
	부스팅이니까 순차적으로 하나씩 처리되고, 그 결과값 바탕으로 또 트리모델 만들고,,
	오차들을 줄여나가겠다 = 부스팅,,, -->오버피팅의 위험성이 커진다.. 정확성은 높아지지만, 실제 데이터의 정확성은,,, 글쎄,,
	-> 단위에 영향을 받을 수 있다....

PCA : 2차원을 어떻게 1차원으로 할거냐,,, 공분산을 이용해서,, 
	어떤 축을 잡아서 fit을 해서 transform 할 것이냐 -> 차원들을 축소해 나갈거야. 
	
	1. 분산을 가장 잘 표현하는 축아서 기준바꾸기. ->변동폭이 큰 아이 찾기(베리언스) -> 그 축이랑 직교되는 축 찾기
	공분산 : 두 변수가 동시에 변하는 정도.
	상관관계 : 공분산을 표준화한 것
	람다 값을 ad-bc=0이 되도록 하는거,, 람다값이 클 수록 변동폭이 큰 것을 의미.. 

DT vs PCA
	DT는 단순히 불필요한 컬럼을 지운거, 해당 컬럼의 데이터는 다 살아있음.
	PCA는 데이터 값도 바뀐 축에 따라서 달라짐


<면접시,,,, 중요한 부분들,,,개념적으로 알아야>
학습의 종류 : 지도학습, 비지도학습 (분류, 회귀, 클러스터링)
학습의 의미
평가지표 :  accuracy, recall precision
트리모형의 특징 
회귀 분석 모형들의 각기 특징점(릿지나 라소에서 제약조건들이 생겼을 때,,, 특징)
앙상블 방법들에 대한 차이점	(부팅, 배깅, 부스팅, 스태킹)
bias, variance----(overfitting, underfitting) : 바이어스와 베리언스를 어떻게 관리할 것인가.. 

DEEP LEARNING 
	대표적인 모델 : DNN, CNN, RNN, LSTM 
	머신러닝 기본 베이스에 위의 모델을 활용.. 
	DT + 여러 NN 혹은 NN만(구조를 어떻게 쓰느냐가 가장 핵심)
MACHINE LEARNING : 
	KNN, SVM, DT, K-MEANS, 인공신경망NN--->딥러닝,,, 
	회귀와 분류쪽,,, 
	일반적인 데이터(인사,,데이터) ->DT 많이 사용
	언어, 음성, 영상


딥러닝 
	성능은 좋아, 그러나 해석이 거의 불가능해...(개, 고양인지는 잘 맞추는데,, 왜 그렇게 인식하는지,,?)
	요즘은 산업분야에 적용하는게 더 이슈,, 새로운 모델이 나오기 보다는,,,  
기본용어
	layer : input layer - hidden layer - output layer
	DNN : deep neural network	 : hidden layer 가 딥해진거 
	여기에 좀 특별하게 cl, pl, fcl이 있다. 
	기능적으로 convolution(, pooling, fully connected 역할을 한다. 
	CNN은 이미지를 분석할 때, 필수!!
CL(convolution layer)
	convolution metrix를 어떻게 잡느냐가 중요!!
		(이미지에 세로의 특성이 잘 드러나면, 매트릭스를 1 0 -1로) 
	기능 : 특징(필터)을 뽑아내기 위해 사용(이미지)
PL(padding layer) 
	패딩 : 오리지널 데이터에 먼저 패딩을 추가한 후 학습!! -->사이즈 맞추려고        
PL(pooling layer)
	pool : 뽑아내는거. 
	maxpooling, averagepooling
최적화 
	local min -> global min 에 어떻게 가까이 할거냐
인공신경망
	비선형 함수들의 최적화
softmax
	multiclass에 대해서 classification 할 때, 필요.
	인풋 아웃풋에 노드들이 있어. 그 노드의 갯수가 같아. 인풋 4개면 아웃풋도 4개
	아웃풋 노드값이 확률로 이루어져,,, 허스키로 나올 값이 몇이구요... 누구의 확률이 가장 높습니다...
	---->이 때 활용되는게 softmax 
	
	핵심 : multiclass에서 쓰고, 아웃풋 레이어에서 쓴다!!! 각각 확률값으로 재조정하는 역할

cost function을 가장 작게 하는 parameter 를 찾는게 중요해

Epoch1(에포크) 
	전체 데이터를 한번 학습하는거
	기능 :인공신경망에서 오버피팅, 언더피팅을 가장 잘 조절할 수 있음 
Batch
	그래디언트를 구하는 단위
DROPOUT
	오버피팅 피하는 방법 중 하나 
	랜덤하게 노드연결을 지우는거 -> 단순한 모델로 만드는거
exp 함수(익스포네이션) : y갑의 차이가 확확 차이나게 

딥러닝에서 가장 중요한 것은 피처 잡는게 아니라 스트럭쳐 구조를 잡는게 가장 중요해

back propagation : 에러값을 줄이기 위해서 적당한 파라미터값을 구하기 위해

<sigmoid -> tanh -> ReLU>
레이어를 너무 많이 쌓으면 (=딥하면) 백으로 파라미터 업데이트를 하다가 가까운 레이어 두세개를 지나면 기울기가 희미해져서 전달을 못해,,,(파라미터 업데이트 못해,, =vanishing gradient problem)
---> 그래서 나온게 ReLU(change activation function)
ReLU
	선형과 비선형을 섞은거
	양수 쪽에서는 기울기가 살아서 업데이트 보장
	
LReLU/PReLU 
	음수도 업데이트 하자!!
ELU
	음수는 스무스 하게, 양수는 확실하게 살리자!!

딥러닝 플랫폼과 툴
	케라스, 파이토치 -->텐서플로우
	텐서플로우가 케라스를 먹었고, 파이토치와 양분화
	텐서는 회사, 파이토치는 연구실에서

텐서플로우
	28x28 이미지 사진(인풋 : 2D)을 1D로 바꿔줘야 해(첫번째 노드에는 첫번째 픽셀,,,) 

adam = 스텝방향과 스텝사이즈 두 가지 모두를 고려한 알고리즘 
	일반적으로 많이 쓴다. 


CNN(Convolution : 이미지에서 컨퍼트르 많이 해서,,, :  Neural Network) :
	이미지에서 쓰이는 필터를 DNN에 적용해보자     
영상처리에서 맥스풀링을 주로 사용함. -> 사이즈가 너무  크다보니까 overpool현상 때문에 

1. 이미지에 패딩-> 2.             
(입력이미지가 컬러면, RGB/ else rgb-->gray    

stride : 
	정의 > 한칸 씩 더 줄여서 매트릭스 크기를 줄이겠다. (한칸이지만, 특성을 그대로 반영될거야)
	기능 >covert를 해도 드라마틱하게 매트릭스가 줄어들지 않아.  -> stride
convolution layer 또한 deep하게 된다. 

<같은 문제를 두 가지 방법으로,,,>
일반적인 DNN구조로 분류모델
이미지들의 특징을 뽑는 conv를 사용하여 CNN모델로 분류해보자 

이후 성능을 향상시키기 위한 방법>>>   
----> 기존에 모델을 사용해서 업글,
----> 주어진 데이터를 바탕으로 임으로 생성함       


CNN : 이미지의 특성을 추출하기 위함.
NN, DNN은 기본적인거고, 그 위에 CNN. RNN이 다른거                

이미지 분류를 위한 NN
--> 일반적인 deep NN : DNN
--> CNN으로 시작함.
	--> 구조변경
		-중간에 pooling(CNN), dropout(NN)
		-conv 레이어를 깊게 쌓기(CNN)...//activation
		-BatchNormalization --> 값을 일정범위로 조정..
			 Dense/Conv -->BN --->Activation 
	--> 데이터 펌핑  : 이미 수집된 데이터로 이리저리 변경하면서 새로운 셋 구성       

RNN
	: 주로 Sequence Data에 관하여 말함
	ex) 주식데이터, 텍스트데이터( 입력단/출력단이 굉장히 Flexible 하다 )

	일반적으로 2-3단 쌓는다
	히든레이어 출력을 옆단으로 넘긴다
	
Vanila RNN 
	: 단순한 구조이지만, 오래된 데이터를 잊어버림 그래서 잘 안씀
	: 히든레이어 아웃풋이 0이라면, 현재 시점의 데이터만 가지고 하기에,,, 안좋아
시그모이드 
	: 0~1, 강도 반영, 얼마나 강하게 반영할거냐
탄젠트 
	: -1~1, 더할거냐 뺄거냐가 중요
                       	

                                              